["{\"transientOutputs\":false,\"transientCellMetadata\":{\"breakpointMargin\":true,\"id\":false,\"metadata\":false,\"attachments\":false},\"transientDocumentMetadata\":{\"cells\":true,\"indentAmount\":true},\"cellContentMetadata\":{\"attachments\":true}}","{\"cells\":[{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"id\":\"f3d42f7b\",\"metadata\":{}},\"outputs\":[],\"source\":\"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom pathlib import Path\\nimport json\\n\\n# Set style\\nsns.set_style(\\\"whitegrid\\\")\\nplt.rcParams['figure.figsize'] = (14, 8)\\n\\n# Define output directory\\noutput_dir = Path(\\\"research_vol/feature_selection\\\")\\n\\nprint(\\\"ðŸ“Š RFECV Volatility Target Analysis\\\")\\nprint(\\\"=\\\" * 80)\",\"internalMetadata\":{\"internalId\":\"6d777fa0\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"id\":\"475b6929\",\"metadata\":{}},\"outputs\":[],\"source\":\"# RFECV Results Analysis - Volatility Forecasting\\n\\nThis notebook analyzes the feature selection results for the `next_24h_vol` regression target.\",\"internalMetadata\":{\"internalId\":\"f2b60953\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"id\":\"daf915e9\",\"metadata\":{}},\"outputs\":[],\"source\":\"## 1. Load Selected Features\",\"internalMetadata\":{\"internalId\":\"7b7e97ec\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"id\":\"ea9cb3a8\",\"metadata\":{}},\"outputs\":[],\"source\":\"# Load selected features\\nwith open(output_dir / \\\"selected_features_rfecv_next_24h_vol_p-100.json\\\", \\\"r\\\") as f:\\n    selected_data = json.load(f)\\n\\nif isinstance(selected_data, dict):\\n    selected_features = selected_data.get(\\\"features\\\", [])\\n    target_percentile = selected_data.get(\\\"target_percentile\\\", -1)\\nelse:\\n    selected_features = selected_data\\n    target_percentile = -1\\n\\nprint(f\\\"\\\\nâœ… Selected Features for next_24h_vol (regression mode)\\\")\\nprint(f\\\"   Target percentile: {target_percentile} (regression sentinel)\\\")\\nprint(f\\\"   Number of selected features: {len(selected_features)}\\\")\\nprint(f\\\"\\\\nðŸ“‹ Selected features:\\\")\\nfor i, feat in enumerate(selected_features, 1):\\n    print(f\\\"   {i:2d}. {feat}\\\")\",\"internalMetadata\":{\"internalId\":\"8681666f\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"id\":\"78acf043\",\"metadata\":{}},\"outputs\":[],\"source\":\"## 2. Feature Importance Analysis\",\"internalMetadata\":{\"internalId\":\"70a0e079\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"id\":\"f52783b0\",\"metadata\":{}},\"outputs\":[],\"source\":\"# Load feature importances\\nimportance_raw = pd.read_csv(output_dir / \\\"feature_importances_raw.csv\\\")\\nimportance_summary = pd.read_csv(output_dir / \\\"feature_importance_summary.csv\\\")\\n\\nprint(\\\"\\\\nðŸ“Š Feature Importance Summary (Top 20)\\\")\\nprint(importance_summary.head(20))\\n\\n# Plot top features by importance\\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\\n\\n# Top 15 by mean importance\\ntop_features = importance_summary.nlargest(15, 'mean_importance')\\naxes[0].barh(range(len(top_features)), top_features['mean_importance'].values)\\naxes[0].set_yticks(range(len(top_features)))\\naxes[0].set_yticklabels(top_features.index)\\naxes[0].set_xlabel('Mean Importance', fontsize=12)\\naxes[0].set_title('Top 15 Features by Mean RFECV Importance', fontsize=14, fontweight='bold')\\naxes[0].invert_yaxis()\\naxes[0].grid(axis='x', alpha=0.3)\\n\\n# Importance distribution\\naxes[1].hist(importance_summary['mean_importance'], bins=30, edgecolor='black', alpha=0.7)\\naxes[1].set_xlabel('Mean Importance', fontsize=12)\\naxes[1].set_ylabel('Frequency', fontsize=12)\\naxes[1].set_title('Distribution of Feature Importances', fontsize=14, fontweight='bold')\\naxes[1].axvline(importance_summary['mean_importance'].median(), color='red', \\n                linestyle='--', linewidth=2, label='Median')\\naxes[1].legend()\\naxes[1].grid(alpha=0.3)\\n\\nplt.tight_layout()\\nplt.show()\",\"internalMetadata\":{\"internalId\":\"828ddd8a\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"id\":\"411b68b6\",\"metadata\":{}},\"outputs\":[],\"source\":\"## 3. Feature Quality Metrics\",\"internalMetadata\":{\"internalId\":\"1347d4a7\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"id\":\"bdd9396f\",\"metadata\":{}},\"outputs\":[],\"source\":\"# Load quality metrics\\nquality_metrics = pd.read_csv(output_dir / \\\"feature_quality_metrics.csv\\\", index_col=0)\\n\\n# Filter to selected features\\nselected_quality = quality_metrics.loc[selected_features].copy()\\n\\nprint(\\\"\\\\nðŸ“ˆ Quality Metrics for Selected Features\\\")\\nprint(selected_quality.describe())\\n\\n# Visualize quality metrics\\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\\n\\n# Non-null ratio\\naxes[0, 0].hist(selected_quality['non_null_ratio'], bins=20, edgecolor='black', alpha=0.7, color='green')\\naxes[0, 0].set_xlabel('Non-Null Ratio', fontsize=12)\\naxes[0, 0].set_ylabel('Frequency', fontsize=12)\\naxes[0, 0].set_title('Data Completeness of Selected Features', fontsize=13, fontweight='bold')\\naxes[0, 0].axvline(0.85, color='red', linestyle='--', linewidth=2, label='Min threshold (0.85)')\\naxes[0, 0].legend()\\naxes[0, 0].grid(alpha=0.3)\\n\\n# Variance\\naxes[0, 1].hist(np.log10(selected_quality['variance'] + 1e-10), bins=30, \\n                edgecolor='black', alpha=0.7, color='blue')\\naxes[0, 1].set_xlabel('Log10(Variance)', fontsize=12)\\naxes[0, 1].set_ylabel('Frequency', fontsize=12)\\naxes[0, 1].set_title('Feature Variance Distribution (log scale)', fontsize=13, fontweight='bold')\\naxes[0, 1].grid(alpha=0.3)\\n\\n# Max absolute correlation\\naxes[1, 0].hist(selected_quality['max_abs_corr'], bins=30, edgecolor='black', alpha=0.7, color='orange')\\naxes[1, 0].set_xlabel('Max Absolute Correlation with Target', fontsize=12)\\naxes[1, 0].set_ylabel('Frequency', fontsize=12)\\naxes[1, 0].set_title('Strongest Target Correlation per Feature', fontsize=13, fontweight='bold')\\naxes[1, 0].grid(alpha=0.3)\\n\\n# Mean absolute correlation\\naxes[1, 1].hist(selected_quality['mean_abs_corr'], bins=30, edgecolor='black', alpha=0.7, color='purple')\\naxes[1, 1].set_xlabel('Mean Absolute Correlation', fontsize=12)\\naxes[1, 1].set_ylabel('Frequency', fontsize=12)\\naxes[1, 1].set_title('Average Target Correlation per Feature', fontsize=13, fontweight='bold')\\naxes[1, 1].grid(alpha=0.3)\\n\\nplt.tight_layout()\\nplt.show()\",\"internalMetadata\":{\"internalId\":\"9cfcfa3d\"}},{\"cellKind\":1,\"language\":\"markdown\",\"metadata\":{\"id\":\"d68edec6\",\"metadata\":{}},\"outputs\":[],\"source\":\"## 4. Feature Categories Analysis\",\"internalMetadata\":{\"internalId\":\"7b99bf7e\"}},{\"cellKind\":2,\"language\":\"python\",\"metadata\":{\"execution_count\":null,\"id\":\"f70c726d\",\"metadata\":{}},\"outputs\":[],\"source\":\"# Categorize features\\ndef categorize_feature(feat_name):\\n    \\\"\\\"\\\"Categorize feature based on naming patterns\\\"\\\"\\\"\\n    feat_lower = feat_name.lower()\\n    \\n    # Volatility features\\n    if any(x in feat_lower for x in ['vol_', 'volatility', 'atr_', 'gkyz']):\\n        return 'Volatility'\\n    \\n    # Returns features\\n    if any(x in feat_lower for x in ['return', 'logret', 'momentum']):\\n        return 'Returns/Momentum'\\n    \\n    # Volume/Liquidity\\n    if any(x in feat_lower for x in ['vlm_', 'volume', 'liquidity']):\\n        return 'Volume/Liquidity'\\n    \\n    # Time features\\n    if any(x in feat_lower for x in ['time_', 'hour', 'day_', 'tte', 'elapsed']):\\n        return 'Temporal'\\n    \\n    # Cycle features\\n    if any(x in feat_lower for x in ['prev_', 'cycle', 'prog', 'exp1', 'exp2']):\\n        return 'Cycle/Historical'\\n    \\n    # Range/Position features\\n    if any(x in feat_lower for x in ['range', 'stoch', 'dist_', 'close_to']):\\n        return 'Range/Position'\\n    \\n    # Technical indicators\\n    if any(x in feat_lower for x in ['macd', 'adx', 'rsi']):\\n        return 'Technical Indicators'\\n    \\n    # Interactions\\n    if '_x_' in feat_lower:\\n        return 'Interactions'\\n    \\n    return 'Other'\\n\\n# Categorize selected features\\ncategories = pd.Series([categorize_feature(f) for f in selected_features], \\n                       index=selected_features, name='Category')\\ncategory_counts = categories.value_counts()\\n\\nprint(\\\"\\\\nðŸ“Š Feature Categories Distribution:\\\")\\nprint(category_counts)\\nprint(f\\\"\\\\nTotal categories: {len(category_counts)}\\\")\\n\\n# Visualize categories\\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\\n\\n# Pie chart\\ncolors = plt.cm.Set3(range(len(category_counts)))\\naxes[0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%',\\n            startangle=90, colors=colors)\\naxes[0].set_title('Feature Categories Distribution', fontsize=14, fontweight='bold')\\n\\n# Bar chart\\naxes[1].barh(range(len(category_counts)), category_counts.values, color=colors)\\naxes[1].set_yticks(range(len(category_counts)))\\naxes[1].set_yticklabels(category_counts.index)\\naxes[1].set_xlabel('Count', fontsize=12)\\naxes[1].set_title('Selected Features by Category', fontsize=14, fontweight='bold')\\naxes[1].invert_yaxis()\\naxes[1].grid(axis='x', alpha=0.3)\\n\\nfor i, v in enumerate(category_counts.values):\\n    axes[1].text(v + 0.1, i, str(v), va='center', fontweight='bold')\\n\\nplt.tight_layout()\\nplt.show()\",\"internalMetadata\":{\"internalId\":\"4939e028\"}}],\"metadata\":{\"metadata\":{},\"nbformat\":4,\"nbformat_minor\":5}}"]