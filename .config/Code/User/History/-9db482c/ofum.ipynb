{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8fd73a",
   "metadata": {},
   "source": [
    "# Feature & Target Pipeline\n",
    "Quick tests and evaluation on new targets/features/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b95c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and configuration ready\n",
      "=== Loading .hist_db_1h.csv ===\n",
      "\n",
      "Initial rows: 53,963\n",
      "\n",
      "=== FOUND ISSUES (prior to automated fixes) ===\n",
      "\n",
      "ðŸ”´ TEMPORAL: Missing hours: 1 cases\n",
      "  Missing timestamps sample:\n",
      "    2025-11-04 13:00:00\n",
      "\n",
      "ðŸ”´ DATA INTEGRITY: Identical consecutive OHLC rows: 174 cases\n",
      "  Sample cases:\n",
      "    {'o': '7110.10', 'h': '7110.10', 'l': '7110.10', 'c': '7110.10', 'volCcy': '0.00'}\n",
      "    {'o': '7110.10', 'h': '7110.10', 'l': '7110.10', 'c': '7110.10', 'volCcy': '0.00'}\n",
      "    {'o': '7110.10', 'h': '7110.10', 'l': '7110.10', 'c': '7110.10', 'volCcy': '0.00'}\n",
      "  Affected dates (sample): 2020-01-02, 2020-01-03, 2020-01-04, 2020-01-05, 2020-01-06\n",
      "\n",
      "=== APPLYING AUTOMATED FIXES ===\n",
      "ACTION: Resampled/Reindexed to 53964 hourly intervals (was 53963).\n",
      "ACTION: Forward-filled NaNs after resampling. (5 NaNs potentially filled by ffill).\n",
      "\n",
      "=== FINAL STATUS (after automated fixes) ===\n",
      "DataFrame shape post-fixes: (53964, 5) (Original: (53963, 6))\n",
      "Date range: 2019-10-01 00:00:00 to 2025-11-26 11:00:00\n",
      "No null values remaining after fixes.\n",
      "Total null values remaining after fixes: 0\n",
      "Loaded raw data: (53964, 5) in 0.07s\n",
      "Using slice: (53964, 5)\n",
      "Heavy cache ready: heavy_features_v1.pkl (total 1) in cache/heavy_features\n",
      "\n",
      "âš  Heavy cache not available; running full fit (slower)\n",
      "[FeatureEngineer] fit start; rows=53964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1584: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sin\"] = df[vol_feat] * df[\"tte_phase_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1586: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_cos\"] = df[vol_feat] * df[\"tte_phase_cos\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1574: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sqrt\"] = df[vol_feat] * tte_sqrt\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1577: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte\"] = df[vol_feat] * tte\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1580: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sq\"] = df[vol_feat] * (tte_normalized ** 2)\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1584: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sin\"] = df[vol_feat] * df[\"tte_phase_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1586: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_cos\"] = df[vol_feat] * df[\"tte_phase_cos\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1591: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte_sqrt\"] = vol_term_slope * tte_sqrt  # Black-Scholes scaling\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1592: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte\"] = vol_term_slope * tte\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1593: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte_sq\"] = vol_term_slope * (tte_normalized ** 2)\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1622: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"volume_weekend_effect\"] = df[\"vlm_ma_24h\"] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1660: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"weekday_vs_saturday_prog\"] = df[\"prev_weekday_ProgActP\"] - df[\"prev_saturday_ProgActP\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1663: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"weekday_vs_sunday_prog\"] = df[\"prev_weekday_ProgActP\"] - df[\"prev_sunday_ProgActP\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prev_cycle_progress_x_hour\"] = df[\"prev_weekday_ProgActP\"] * df[\"hour_of_week_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1676: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"extreme_range_vol\"] = df[\"compressed_range_vol\"] * df[\"vol_gkyz_3h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1680: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"skew_vol_extreme\"] = df[\"returns_skew_24h\"] * df[\"vol_gkyz_6h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1684: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"kurtosis_vol_extreme\"] = df[\"returns_kurtosis_24h\"] * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1688: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"distance_vol_extreme\"] = df[\"dist_from_high_144h\"] * df[\"vol_gkyz_24h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1692: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_surprise_clustering\"] = df[\"volume_surprise\"] * df[\"vol_clustering\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureEngineer] feature build complete; rows=53964, cols=450, total=173.38s [stateless:251.9ms, merge_stateless:2.4ms, temporal:15.7ms, rolling:642.0ms, prev_week_cycle:163155.7ms, current_cycle:8857.9ms, non_linear:265.1ms, custom_interactions:27.0ms, cleanup:167.2ms]\n",
      "[FeatureEngineer] fit complete; rows=53964, cols=450, elapsed=173.39s\n",
      "[FeatureEngineer] transform start; rows=53964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1584: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sin\"] = df[vol_feat] * df[\"tte_phase_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1586: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_cos\"] = df[vol_feat] * df[\"tte_phase_cos\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1574: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sqrt\"] = df[vol_feat] * tte_sqrt\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1577: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte\"] = df[vol_feat] * tte\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1580: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sq\"] = df[vol_feat] * (tte_normalized ** 2)\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1584: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_sin\"] = df[vol_feat] * df[\"tte_phase_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1586: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_x_tte_cos\"] = df[vol_feat] * df[\"tte_phase_cos\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1591: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte_sqrt\"] = vol_term_slope * tte_sqrt  # Black-Scholes scaling\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1592: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte\"] = vol_term_slope * tte\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1593: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_term_x_tte_sq\"] = vol_term_slope * (tte_normalized ** 2)\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekend\"] = df[vol_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{vol_feat}_weekday\"] = df[vol_feat] * (1 - df[\"is_weekend\"])\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{prev_feat}_weekend\"] = df[prev_feat] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1622: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"volume_weekend_effect\"] = df[\"vlm_ma_24h\"] * df[\"is_weekend\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[prog_feature] * df[vol_feat]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1656: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{cycle_type}_range_x_vol\"] = cycle_range * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1660: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"weekday_vs_saturday_prog\"] = df[\"prev_weekday_ProgActP\"] - df[\"prev_saturday_ProgActP\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1663: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"weekday_vs_sunday_prog\"] = df[\"prev_weekday_ProgActP\"] - df[\"prev_sunday_ProgActP\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"prev_cycle_progress_x_hour\"] = df[\"prev_weekday_ProgActP\"] * df[\"hour_of_week_sin\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1676: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"extreme_range_vol\"] = df[\"compressed_range_vol\"] * df[\"vol_gkyz_3h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1680: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"skew_vol_extreme\"] = df[\"returns_skew_24h\"] * df[\"vol_gkyz_6h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1684: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"kurtosis_vol_extreme\"] = df[\"returns_kurtosis_24h\"] * df[\"vol_gkyz_12h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1688: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"distance_vol_extreme\"] = df[\"dist_from_high_144h\"] * df[\"vol_gkyz_24h\"]\n",
      "/shared/eastSync/pyEast/pro_version/featureEngineer.py:1692: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"vol_surprise_clustering\"] = df[\"volume_surprise\"] * df[\"vol_clustering\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureEngineer] feature build complete; rows=53964, cols=450, total=10.51s [stateless:234.7ms, merge_stateless:2.1ms, temporal:12.9ms, rolling:639.1ms, prev_week_cycle:51.9ms, current_cycle:9106.4ms, non_linear:264.7ms, custom_interactions:28.5ms, cleanup:168.7ms]\n",
      "[FeatureEngineer] transform complete; rows=53964, cols=450, elapsed=10.51s\n",
      "  Full fit+transform in 183.90s -> shape: (53964, 450)\n",
      "\n",
      "--- Building Volatility Regime Targets ---\n",
      "Regime targets built in 340.01s -> shape: (53964, 6)\n",
      "Regime targets built in 340.01s -> shape: (53964, 6)\n",
      "\n",
      "Regime distribution:\n",
      "regime_label\n",
      "0    43673\n",
      "1     6364\n",
      "2     3795\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Combined shape: (53964, 456)\n",
      "Total pipeline time: 862.56s\n",
      "\n",
      "Regime distribution:\n",
      "regime_label\n",
      "0    43673\n",
      "1     6364\n",
      "2     3795\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Combined shape: (53964, 456)\n",
      "Total pipeline time: 862.56s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import time\n",
    "from data_pipeline import load_data  # This just loads the data and cleans it\n",
    "from featureEngineer import FeatureEngineer\n",
    "from targetEngineer import ExpirationTargetEngineer\n",
    "from ML_setup import CONFIG\n",
    "from ML_general_tools import *\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Imports and configuration ready\")\n",
    "\n",
    "# Build features, targets, and combined dataframe\n",
    "t0 = time.time()\n",
    "raw_history = load_data(CONFIG[\"data\"][\"path\"])\n",
    "print(f\"Loaded raw data: {raw_history.shape} in {time.time()-t0:.2f}s\")\n",
    "\n",
    "# Use slice for faster testing (or use [:] for full data)\n",
    "history_slice = raw_history[:]  # Last 3000 rows for faster testing\n",
    "print(f\"Using slice: {history_slice.shape}\")\n",
    "\n",
    "feature_params = dict(CONFIG[\"features\"][\"params\"])\n",
    "heavy_cache_cfg = CONFIG[\"features\"].get(\"heavy_cache\", {})\n",
    "heavy_cache_root = Path(heavy_cache_cfg.get(\"directory\", \"cache/heavy_features\"))\n",
    "\n",
    "current_output_root_str = CONFIG[\"output\"][\"directory\"]\n",
    "current_output_root_path = Path(current_output_root_str)\n",
    "\n",
    "paths = {\n",
    "    \"root\": current_output_root_path,\n",
    "    \"feature_selection\": current_output_root_path / CONFIG[\"output\"][\"subdirectories\"][\"features\"],\n",
    "    \"trained_models\": current_output_root_path / CONFIG[\"output\"][\"subdirectories\"][\"models\"],\n",
    "    \"hpt_studies\": current_output_root_path / CONFIG[\"output\"][\"subdirectories\"][\"hpt\"],\n",
    "    \"feature_cache\": current_output_root_path / CONFIG[\"output\"][\"subdirectories\"][\"cache\"]\n",
    "}\n",
    "\n",
    "cache_dir = heavy_cache_root\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "cache_files = sorted(cache_dir.glob(\"heavy_features_v*.pkl\"))\n",
    "cache_ready = bool(cache_files)\n",
    "if cache_ready:\n",
    "    print(f\"Heavy cache ready: {cache_files[-1].name} (total {len(cache_files)}) in {cache_dir}\")\n",
    "else:\n",
    "    print(f\"No heavy cache file found in {cache_dir}; initial fit will populate.\")\n",
    "\n",
    "## Feature Engineering\n",
    "fe = FeatureEngineer(verbose=True, **{k: v for k, v in feature_params.items() if k != \"verbose\"})\n",
    "\n",
    "## Cache usage\n",
    "cache_ready = bool(cache_files)  # Use actual cache status\n",
    "cache_ready = False\n",
    "manual_features = None\n",
    "if cache_ready and fe.heavy_cache.load():\n",
    "    print(\"\\nâœ“ Using heavy cache (only prev_cycle features cached)\")\n",
    "    print(\"  Note: Rolling/stateless features still computed on-the-fly\")\n",
    "    t1 = time.time()\n",
    "    fe._heavy_payload = fe.heavy_cache.payload\n",
    "    reference = fe._prepare_reference_frame(history_slice)\n",
    "    fe._full_reference = reference\n",
    "    manual_features = fe._compute_all_features(reference, build_heavy=False)\n",
    "    fe.feature_names_out_ = manual_features.columns.tolist()\n",
    "    fe._reference_features = manual_features\n",
    "    print(f\"  Features computed in {time.time()-t1:.2f}s -> shape: {manual_features.shape}\")\n",
    "else:\n",
    "    print(\"\\nâš  Heavy cache not available; running full fit (slower)\")\n",
    "    t1 = time.time()\n",
    "    verbose_flag = feature_params.pop(\"verbose\", False)\n",
    "    fe = FeatureEngineer(verbose=True, **feature_params)\n",
    "    fe.fit(history_slice)\n",
    "    manual_features = fe.transform(history_slice)\n",
    "    print(f\"  Full fit+transform in {time.time()-t1:.2f}s -> shape: {manual_features.shape}\")\n",
    "\n",
    "feature_engineer = fe\n",
    "features = manual_features.copy()\n",
    "\n",
    "## 2a. Volatility Regime Target Engineering ---\n",
    "from targetEngineer import VolatilityRegimeEngineer\n",
    "\n",
    "print(\"\\n--- Building Volatility Regime Targets ---\")\n",
    "t2 = time.time()\n",
    "\n",
    "regime_engineer = VolatilityRegimeEngineer(\n",
    "    lookback_window=24*3,    # 3 days lookback for vol\n",
    "    seasonal_window=24*30,   # 30 days to learn patterns\n",
    "    forward_window=24,       # 24h classification\n",
    "    trend_std=1.2,           # 1.2 daily sigmas\n",
    "    jump_std=3.0,            # 3.0 daily sigmas\n",
    "    jump_speed_window=6,     # 6h window for jump detection\n",
    ")\n",
    "\n",
    "regime_engineer.fit(features)\n",
    "targets = regime_engineer.transform(features)\n",
    "print(f\"Regime targets built in {time.time()-t2:.2f}s -> shape: {targets.shape}\")\n",
    "\n",
    "# Check distribution\n",
    "dist = regime_engineer.get_regime_distribution(features)\n",
    "print(\"\\nRegime distribution:\")\n",
    "print(dist)\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([features, targets], axis=1)\n",
    "print(f\"\\nCombined shape: {combined_df.shape}\")\n",
    "print(f\"Total pipeline time: {time.time()-t0:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Cache not found or FORCE_REBUILD=True - will save after first run\n",
      "To use cache next time:\n",
      "  1. Run the first cell with history_slice = raw_history[:]\n",
      "  2. Wait for features/targets to compute\n",
      "  3. This cell will save them\n",
      "  4. Next time, set FORCE_REBUILD=False and skip the first cell\n",
      "============================================================\n",
      "\n",
      "Saving current features and targets to cache...\n",
      "âœ“ Saved to cache in 0.44s\n",
      "  Location: research_vol\n",
      "âœ“ Saved to cache in 0.44s\n",
      "  Location: research_vol\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Define cache paths\n",
    "cache_root = paths[\"root\"]\n",
    "cache_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "feature_cache = cache_root / \"features_cache.pkl\"\n",
    "target_cache = cache_root / \"targets_cache.pkl\"\n",
    "combined_cache = cache_root / \"combined_cache.pkl\"\n",
    "\n",
    "# Option 1: Load from cache if exists\n",
    "FORCE_REBUILD = False  # Set to True to rebuild from scratch\n",
    "\n",
    "if not FORCE_REBUILD and feature_cache.exists() and target_cache.exists():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Loading cached features and targets...\")\n",
    "    t_load = time.time()\n",
    "    \n",
    "    with open(feature_cache, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    with open(target_cache, 'rb') as f:\n",
    "        targets = pickle.load(f)\n",
    "    with open(combined_cache, 'rb') as f:\n",
    "        combined_df = pickle.load(f)\n",
    "    \n",
    "    print(f\"âœ“ Loaded from cache in {time.time()-t_load:.2f}s\")\n",
    "    print(f\"  Features: {features.shape}\")\n",
    "    print(f\"  Targets: {targets.shape}\")\n",
    "    print(f\"  Combined: {combined_df.shape}\")\n",
    "    print(f\"  Date range: {features.index[0]} to {features.index[-1]}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Cache not found or FORCE_REBUILD=True - will save after first run\")\n",
    "    print(\"To use cache next time:\")\n",
    "    print(\"  1. Run the first cell with history_slice = raw_history[:]\")\n",
    "    print(\"  2. Wait for features/targets to compute\")\n",
    "    print(\"  3. This cell will save them\")\n",
    "    print(\"  4. Next time, set FORCE_REBUILD=False and skip the first cell\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Save the current run to cache\n",
    "    if 'features' in globals() and 'targets' in globals():\n",
    "        print(\"\\nSaving current features and targets to cache...\")\n",
    "        t_save = time.time()\n",
    "        \n",
    "        with open(feature_cache, 'wb') as f:\n",
    "            pickle.dump(features, f)\n",
    "        with open(target_cache, 'wb') as f:\n",
    "            pickle.dump(targets, f)\n",
    "        with open(combined_cache, 'wb') as f:\n",
    "            pickle.dump(combined_df, f)\n",
    "        \n",
    "        print(f\"âœ“ Saved to cache in {time.time()-t_save:.2f}s\")\n",
    "        print(f\"  Location: {cache_root}\")\n",
    "    else:\n",
    "        print(\"âš  No features/targets to save yet - run the first cell first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea14ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NaN Analysis in Features\n",
      "======================================================================\n",
      "\n",
      "Total features: 450\n",
      "Features with NaNs: 207\n",
      "Total rows: 53964\n",
      "\n",
      "======================================================================\n",
      "NaN Features Grouped by Source:\n",
      "======================================================================\n",
      "\n",
      "VOL features: 53 features, 2,697 total NaNs\n",
      "  vol_gkyz_288h_x_tte_sqrt                              288 NaNs ( 0.53%)\n",
      "  vol_gkyz_288h_x_tte                                   288 NaNs ( 0.53%)\n",
      "  vol_gkyz_288h_x_tte_cos                               288 NaNs ( 0.53%)\n",
      "  vol_gkyz_288h_x_tte_sin                               288 NaNs ( 0.53%)\n",
      "  vol_gkyz_288h_x_tte_sq                                288 NaNs ( 0.53%)\n",
      "\n",
      "STOCH features: 7 features, 1,032 total NaNs\n",
      "  stoch_pos_3h                                          173 NaNs ( 0.32%)\n",
      "  stoch_pos_6h                                          169 NaNs ( 0.31%)\n",
      "  stoch_pos_12h                                         162 NaNs ( 0.30%)\n",
      "  stoch_pos_24h                                         156 NaNs ( 0.29%)\n",
      "  stoch_pos_288h                                        144 NaNs ( 0.27%)\n",
      "\n",
      "VLM features: 18 features, 597 total NaNs\n",
      "  vlm_zscore_288h                                       144 NaNs ( 0.27%)\n",
      "  vlm_ma_288h                                           144 NaNs ( 0.27%)\n",
      "  vlm_ma_144h                                            72 NaNs ( 0.13%)\n",
      "  vlm_zscore_144h                                        72 NaNs ( 0.13%)\n",
      "  vlm_zscore_72h                                         36 NaNs ( 0.07%)\n",
      "\n",
      "PRICE features: 7 features, 549 total NaNs\n",
      "  price_rank_288h                                       288 NaNs ( 0.53%)\n",
      "  price_rank_144h                                       144 NaNs ( 0.27%)\n",
      "  price_rank_72h                                         72 NaNs ( 0.13%)\n",
      "  price_rank_24h                                         24 NaNs ( 0.04%)\n",
      "  price_rank_12h                                         12 NaNs ( 0.02%)\n",
      "\n",
      "DIST features: 14 features, 548 total NaNs\n",
      "  dist_from_low_288h                                    144 NaNs ( 0.27%)\n",
      "  dist_from_high_288h                                   144 NaNs ( 0.27%)\n",
      "  dist_from_low_144h                                     72 NaNs ( 0.13%)\n",
      "  dist_from_high_144h                                    72 NaNs ( 0.13%)\n",
      "  dist_from_high_72h                                     36 NaNs ( 0.07%)\n",
      "\n",
      "PREV features: 40 features, 541 total NaNs\n",
      "  prev_saturday_ProgMinP_x_vol24h                        24 NaNs ( 0.04%)\n",
      "  prev_sunday_ProgMaxP_x_vol24h                          24 NaNs ( 0.04%)\n",
      "  prev_sunday_ProgVlm_x_vol24h                           24 NaNs ( 0.04%)\n",
      "  prev_sunday_ProgActP_x_vol24h                          24 NaNs ( 0.04%)\n",
      "  prev_saturday_ProgMaxP_x_vol24h                        24 NaNs ( 0.04%)\n",
      "\n",
      "EXTREME features: 6 features, 154 total NaNs\n",
      "  extreme_prob                                           26 NaNs ( 0.05%)\n",
      "  extreme_prob_x_tte                                     26 NaNs ( 0.05%)\n",
      "  extreme_prob_x_tte_cu                                  26 NaNs ( 0.05%)\n",
      "  extreme_prob_x_tte_sq                                  26 NaNs ( 0.05%)\n",
      "  extreme_prob_x_tte_sqrt                                26 NaNs ( 0.05%)\n",
      "\n",
      "LOGRET features: 11 features, 142 total NaNs\n",
      "  logret_72h                                             73 NaNs ( 0.14%)\n",
      "  logret_24h                                             25 NaNs ( 0.05%)\n",
      "  logret_12h                                             13 NaNs ( 0.02%)\n",
      "  logret_6h                                               7 NaNs ( 0.01%)\n",
      "  logret_5h                                               6 NaNs ( 0.01%)\n",
      "\n",
      "REALIZED features: 2 features, 142 total NaNs\n",
      "  realized_to_expected_24h                               71 NaNs ( 0.13%)\n",
      "  realized_to_expected_tte                               71 NaNs ( 0.13%)\n",
      "\n",
      "DISTANCE features: 1 features, 72 total NaNs\n",
      "  distance_vol_extreme                                   72 NaNs ( 0.13%)\n",
      "\n",
      "======================================================================\n",
      "NaN Location Analysis (Top 10 worst features):\n",
      "======================================================================\n",
      "\n",
      "price_rank_288h:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h_x_tte_sqrt:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h_x_tte:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h_x_tte_cos:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h_x_tte_sin:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h_x_tte_sq:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "vol_gkyz_288h:\n",
      "  Total NaNs: 288 (0.53%)\n",
      "  Start NaNs: 287 (before 2019-10-13 00:00:00)\n",
      "  Middle NaNs: 2\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "stoch_pos_3h:\n",
      "  Total NaNs: 173 (0.32%)\n",
      "  Start NaNs: 0 (before 2019-10-01 01:00:00)\n",
      "  Middle NaNs: 174\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "stoch_pos_6h:\n",
      "  Total NaNs: 169 (0.31%)\n",
      "  Start NaNs: 2 (before 2019-10-01 03:00:00)\n",
      "  Middle NaNs: 168\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "stoch_pos_12h:\n",
      "  Total NaNs: 162 (0.30%)\n",
      "  Start NaNs: 5 (before 2019-10-01 06:00:00)\n",
      "  Middle NaNs: 158\n",
      "  End NaNs: -1 (after 2025-11-26 11:00:00)\n",
      "\n",
      "======================================================================\n",
      "Expected NaN Sources (prev_weekend, empirical, etc.):\n",
      "======================================================================\n",
      "\n",
      "prev_saturday/sunday features with NaNs: 26\n",
      "  prev_saturday_ProgMinP_x_vol24h: 24 NaNs\n",
      "  prev_sunday_ProgMaxP_x_vol24h: 24 NaNs\n",
      "  prev_sunday_ProgVlm_x_vol24h: 24 NaNs\n",
      "  prev_sunday_ProgActP_x_vol24h: 24 NaNs\n",
      "  prev_saturday_ProgMaxP_x_vol24h: 24 NaNs\n",
      "\n",
      "emp_ (empirical) features with NaNs: 0\n",
      "\n",
      "prev_weekday features with NaNs: 13\n",
      "  prev_weekday_ProgMinP_x_vol24h: 24 NaNs\n",
      "  prev_weekday_ProgMaxP_x_vol24h: 24 NaNs\n",
      "  prev_weekday_ProgActP_x_vol24h: 24 NaNs\n",
      "  prev_weekday_ProgVlm_x_vol24h: 24 NaNs\n",
      "  prev_weekday_range_x_vol: 12 NaNs\n",
      "\n",
      "======================================================================\n",
      "Row-wise NaN Analysis:\n",
      "======================================================================\n",
      "Rows with ANY NaNs: 460 / 53,964 (0.85%)\n",
      "First row with NaNs: 2019-10-01 00:00:00\n",
      "Last row with NaNs: 2022-12-18 18:00:00\n",
      "Consecutive NaN rows at start: 288\n",
      "Consecutive NaN rows at end: 0\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive NaN analysis in features\n",
    "print(\"=\" * 70)\n",
    "print(\"NaN Analysis in Features\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Overall NaN statistics\n",
    "nan_counts = features.isna().sum()\n",
    "nan_features = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nTotal features: {len(features.columns)}\")\n",
    "print(f\"Features with NaNs: {len(nan_features)}\")\n",
    "print(f\"Total rows: {len(features)}\")\n",
    "\n",
    "# 2. Group NaN features by prefix to identify source\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NaN Features Grouped by Source:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "feature_groups = {}\n",
    "for feat in nan_features.index:\n",
    "    # Extract prefix (everything before first underscore or digit)\n",
    "    if '_' in feat:\n",
    "        prefix = feat.split('_')[0]\n",
    "    else:\n",
    "        prefix = 'other'\n",
    "    \n",
    "    if prefix not in feature_groups:\n",
    "        feature_groups[prefix] = []\n",
    "    feature_groups[prefix].append((feat, nan_counts[feat]))\n",
    "\n",
    "# Sort groups by total NaN count\n",
    "sorted_groups = sorted(feature_groups.items(), \n",
    "                       key=lambda x: sum(count for _, count in x[1]), \n",
    "                       reverse=True)\n",
    "\n",
    "for prefix, features_list in sorted_groups[:10]:  # Top 10 groups\n",
    "    total_nans = sum(count for _, count in features_list)\n",
    "    print(f\"\\n{prefix.upper()} features: {len(features_list)} features, {total_nans:,} total NaNs\")\n",
    "    # Show top 5 within each group\n",
    "    for feat, count in sorted(features_list, key=lambda x: x[1], reverse=True)[:5]:\n",
    "        pct = (count / len(features)) * 100\n",
    "        print(f\"  {feat:50s} {count:6,} NaNs ({pct:5.2f}%)\")\n",
    "\n",
    "# 3. Analyze NaN patterns (start/middle/end)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NaN Location Analysis (Top 10 worst features):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for feat in nan_features.head(10).index:\n",
    "    series = features[feat]\n",
    "    nan_mask = series.isna()\n",
    "    \n",
    "    # Find first and last valid index\n",
    "    valid_indices = series[~nan_mask].index\n",
    "    if len(valid_indices) == 0:\n",
    "        print(f\"\\n{feat}: ALL NaNs!\")\n",
    "        continue\n",
    "    \n",
    "    first_valid = valid_indices[0]\n",
    "    last_valid = valid_indices[-1]\n",
    "    \n",
    "    # Count NaNs at start, middle, end\n",
    "    start_nans = nan_mask.loc[:first_valid].sum() - 1  # -1 to exclude first valid\n",
    "    end_nans = nan_mask.loc[last_valid:].sum() - 1  # -1 to exclude last valid\n",
    "    middle_nans = nan_mask.sum() - start_nans - end_nans\n",
    "    \n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"  Total NaNs: {nan_mask.sum():,} ({nan_mask.sum()/len(features)*100:.2f}%)\")\n",
    "    print(f\"  Start NaNs: {start_nans:,} (before {first_valid})\")\n",
    "    print(f\"  Middle NaNs: {middle_nans:,}\")\n",
    "    print(f\"  End NaNs: {end_nans:,} (after {last_valid})\")\n",
    "\n",
    "# 4. Check specific feature types that are expected\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Expected NaN Sources (prev_weekend, empirical, etc.):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prev_weekend_features = [f for f in nan_features.index if 'prev_saturday' in f or 'prev_sunday' in f]\n",
    "empirical_features = [f for f in nan_features.index if 'emp_' in f]\n",
    "prev_weekday_features = [f for f in nan_features.index if 'prev_weekday' in f]\n",
    "\n",
    "print(f\"\\nprev_saturday/sunday features with NaNs: {len(prev_weekend_features)}\")\n",
    "if prev_weekend_features:\n",
    "    for feat in prev_weekend_features[:5]:\n",
    "        print(f\"  {feat}: {nan_counts[feat]:,} NaNs\")\n",
    "\n",
    "print(f\"\\nemp_ (empirical) features with NaNs: {len(empirical_features)}\")\n",
    "if empirical_features:\n",
    "    for feat in empirical_features[:5]:\n",
    "        print(f\"  {feat}: {nan_counts[feat]:,} NaNs\")\n",
    "\n",
    "print(f\"\\nprev_weekday features with NaNs: {len(prev_weekday_features)}\")\n",
    "if prev_weekday_features:\n",
    "    for feat in prev_weekday_features[:5]:\n",
    "        print(f\"  {feat}: {nan_counts[feat]:,} NaNs\")\n",
    "\n",
    "# 5. Check which rows have NaNs\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Row-wise NaN Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rows_with_nans = features.isna().any(axis=1)\n",
    "print(f\"Rows with ANY NaNs: {rows_with_nans.sum():,} / {len(features):,} ({rows_with_nans.sum()/len(features)*100:.2f}%)\")\n",
    "\n",
    "# Show first and last rows with NaNs\n",
    "nan_row_indices = features[rows_with_nans].index\n",
    "if len(nan_row_indices) > 0:\n",
    "    print(f\"First row with NaNs: {nan_row_indices[0]}\")\n",
    "    print(f\"Last row with NaNs: {nan_row_indices[-1]}\")\n",
    "    \n",
    "    # Count consecutive NaNs at start and end\n",
    "    consecutive_start = 0\n",
    "    for i in range(len(rows_with_nans)):\n",
    "        if rows_with_nans.iloc[i]:\n",
    "            consecutive_start += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    consecutive_end = 0\n",
    "    for i in range(len(rows_with_nans)-1, -1, -1):\n",
    "        if rows_with_nans.iloc[i]:\n",
    "            consecutive_end += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(f\"Consecutive NaN rows at start: {consecutive_start}\")\n",
    "    print(f\"Consecutive NaN rows at end: {consecutive_end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8f63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Summary:\n",
      "  First valid row: 2019-10-13 00:00:00\n",
      "  Last valid row: 2025-11-26 10:00:00\n",
      "  Start NaNs to drop: 287\n",
      "  End NaNs to drop: 0\n",
      "\n",
      "After trimming start/end:\n",
      "  Rows: 53675 (from 2019-10-13 00:00:00 to 2025-11-26 10:00:00)\n",
      "  Middle rows with NaNs: 97\n",
      "  âš ï¸ WARNING: 97 rows with NaNs in middle - preserved for debugging\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>c</th>\n",
       "      <th>volCcy</th>\n",
       "      <th>time_to_exp1_hr</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>skew_vol_extreme</th>\n",
       "      <th>kurtosis_vol_extreme</th>\n",
       "      <th>distance_vol_extreme</th>\n",
       "      <th>vol_surprise_clustering</th>\n",
       "      <th>regime_label</th>\n",
       "      <th>max_fwd_z_score</th>\n",
       "      <th>max_jump_z_score</th>\n",
       "      <th>box_std_deseasonalized</th>\n",
       "      <th>box_std_raw</th>\n",
       "      <th>seasonal_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-13 00:00:00</th>\n",
       "      <td>8308.5</td>\n",
       "      <td>8341.3</td>\n",
       "      <td>8289.9</td>\n",
       "      <td>8336.7</td>\n",
       "      <td>718.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361831</td>\n",
       "      <td>-0.141242</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>-2.814803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687067</td>\n",
       "      <td>1.374134</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13 01:00:00</th>\n",
       "      <td>8336.7</td>\n",
       "      <td>8368.5</td>\n",
       "      <td>8336.7</td>\n",
       "      <td>8349.9</td>\n",
       "      <td>796.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325121</td>\n",
       "      <td>-0.212071</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>-0.215035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>1.803030</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13 02:00:00</th>\n",
       "      <td>8350.0</td>\n",
       "      <td>8358.6</td>\n",
       "      <td>8340.0</td>\n",
       "      <td>8346.9</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329969</td>\n",
       "      <td>-0.205131</td>\n",
       "      <td>0.014965</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720972</td>\n",
       "      <td>1.441945</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.003420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13 03:00:00</th>\n",
       "      <td>8346.9</td>\n",
       "      <td>8348.0</td>\n",
       "      <td>8340.0</td>\n",
       "      <td>8345.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330016</td>\n",
       "      <td>-0.225318</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>-1.322802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>1.276600</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13 04:00:00</th>\n",
       "      <td>8345.0</td>\n",
       "      <td>8363.4</td>\n",
       "      <td>8341.1</td>\n",
       "      <td>8341.7</td>\n",
       "      <td>576.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364801</td>\n",
       "      <td>-0.232202</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>-3.175828</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>1.576923</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.003822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26 06:00:00</th>\n",
       "      <td>87452.5</td>\n",
       "      <td>87827.3</td>\n",
       "      <td>87383.4</td>\n",
       "      <td>87733.9</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>-1.329192</td>\n",
       "      <td>0.032090</td>\n",
       "      <td>-9.314568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26 07:00:00</th>\n",
       "      <td>87725.2</td>\n",
       "      <td>87900.0</td>\n",
       "      <td>87637.7</td>\n",
       "      <td>87872.6</td>\n",
       "      <td>195.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>-1.149395</td>\n",
       "      <td>0.028068</td>\n",
       "      <td>-1.972040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26 08:00:00</th>\n",
       "      <td>87872.7</td>\n",
       "      <td>87881.8</td>\n",
       "      <td>87342.9</td>\n",
       "      <td>87361.7</td>\n",
       "      <td>232.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>-1.115242</td>\n",
       "      <td>0.026972</td>\n",
       "      <td>-6.318691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.003427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26 09:00:00</th>\n",
       "      <td>87353.5</td>\n",
       "      <td>87396.7</td>\n",
       "      <td>86627.9</td>\n",
       "      <td>86776.2</td>\n",
       "      <td>567.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054797</td>\n",
       "      <td>-1.139544</td>\n",
       "      <td>0.030126</td>\n",
       "      <td>-4.989376</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.004367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26 10:00:00</th>\n",
       "      <td>86772.2</td>\n",
       "      <td>86999.9</td>\n",
       "      <td>86595.8</td>\n",
       "      <td>86879.7</td>\n",
       "      <td>195.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108033</td>\n",
       "      <td>-0.985923</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>7.130272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53675 rows Ã— 456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           o        h        l        c  volCcy  \\\n",
       "2019-10-13 00:00:00   8308.5   8341.3   8289.9   8336.7   718.0   \n",
       "2019-10-13 01:00:00   8336.7   8368.5   8336.7   8349.9   796.0   \n",
       "2019-10-13 02:00:00   8350.0   8358.6   8340.0   8346.9   421.0   \n",
       "2019-10-13 03:00:00   8346.9   8348.0   8340.0   8345.0   154.0   \n",
       "2019-10-13 04:00:00   8345.0   8363.4   8341.1   8341.7   576.0   \n",
       "...                      ...      ...      ...      ...     ...   \n",
       "2025-11-26 06:00:00  87452.5  87827.3  87383.4  87733.9   338.0   \n",
       "2025-11-26 07:00:00  87725.2  87900.0  87637.7  87872.6   195.0   \n",
       "2025-11-26 08:00:00  87872.7  87881.8  87342.9  87361.7   232.0   \n",
       "2025-11-26 09:00:00  87353.5  87396.7  86627.9  86776.2   567.0   \n",
       "2025-11-26 10:00:00  86772.2  86999.9  86595.8  86879.7   195.0   \n",
       "\n",
       "                     time_to_exp1_hr  time_elapsed  hour  day_of_week  \\\n",
       "2019-10-13 00:00:00              7.0          17.0     1            6   \n",
       "2019-10-13 01:00:00              6.0          18.0     2            6   \n",
       "2019-10-13 02:00:00              5.0          19.0     3            6   \n",
       "2019-10-13 03:00:00              4.0          20.0     4            6   \n",
       "2019-10-13 04:00:00              3.0          21.0     5            6   \n",
       "...                              ...           ...   ...          ...   \n",
       "2025-11-26 06:00:00              1.0          23.0     7            2   \n",
       "2025-11-26 07:00:00             24.0           0.0     8            2   \n",
       "2025-11-26 08:00:00             23.0           1.0     9            2   \n",
       "2025-11-26 09:00:00             22.0           2.0    10            2   \n",
       "2025-11-26 10:00:00             21.0           3.0    11            2   \n",
       "\n",
       "                     is_weekend  ...  skew_vol_extreme  kurtosis_vol_extreme  \\\n",
       "2019-10-13 00:00:00           1  ...         -0.361831             -0.141242   \n",
       "2019-10-13 01:00:00           1  ...         -0.325121             -0.212071   \n",
       "2019-10-13 02:00:00           1  ...         -0.329969             -0.205131   \n",
       "2019-10-13 03:00:00           1  ...         -0.330016             -0.225318   \n",
       "2019-10-13 04:00:00           1  ...         -0.364801             -0.232202   \n",
       "...                         ...  ...               ...                   ...   \n",
       "2025-11-26 06:00:00           0  ...          0.005392             -1.329192   \n",
       "2025-11-26 07:00:00           0  ...          0.013903             -1.149395   \n",
       "2025-11-26 08:00:00           0  ...          0.014572             -1.115242   \n",
       "2025-11-26 09:00:00           0  ...         -0.054797             -1.139544   \n",
       "2025-11-26 10:00:00           0  ...         -0.108033             -0.985923   \n",
       "\n",
       "                     distance_vol_extreme  vol_surprise_clustering  \\\n",
       "2019-10-13 00:00:00              0.016816                -2.814803   \n",
       "2019-10-13 01:00:00              0.015524                -0.215035   \n",
       "2019-10-13 02:00:00              0.014965                 0.169210   \n",
       "2019-10-13 03:00:00              0.015040                -1.322802   \n",
       "2019-10-13 04:00:00              0.015188                -3.175828   \n",
       "...                                   ...                      ...   \n",
       "2025-11-26 06:00:00              0.032090                -9.314568   \n",
       "2025-11-26 07:00:00              0.028068                -1.972040   \n",
       "2025-11-26 08:00:00              0.026972                -6.318691   \n",
       "2025-11-26 09:00:00              0.030126                -4.989376   \n",
       "2025-11-26 10:00:00              0.033643                 7.130272   \n",
       "\n",
       "                     regime_label  max_fwd_z_score  max_jump_z_score  \\\n",
       "2019-10-13 00:00:00             0         0.687067          1.374134   \n",
       "2019-10-13 01:00:00             0         0.901515          1.803030   \n",
       "2019-10-13 02:00:00             0         0.720972          1.441945   \n",
       "2019-10-13 03:00:00             0         0.638300          1.276600   \n",
       "2019-10-13 04:00:00             0         0.788462          1.576923   \n",
       "...                           ...              ...               ...   \n",
       "2025-11-26 06:00:00             0         0.391165          0.000000   \n",
       "2025-11-26 07:00:00             0         0.467373          0.000000   \n",
       "2025-11-26 08:00:00             0         0.249501          0.000000   \n",
       "2025-11-26 09:00:00             0         0.092720          0.000000   \n",
       "2025-11-26 10:00:00             0         0.017461          0.000000   \n",
       "\n",
       "                     box_std_deseasonalized  box_std_raw  seasonal_vol  \n",
       "2019-10-13 00:00:00                0.006729     0.005135      0.003437  \n",
       "2019-10-13 01:00:00                0.005487     0.005147      0.004225  \n",
       "2019-10-13 02:00:00                0.006759     0.005132      0.003420  \n",
       "2019-10-13 03:00:00                0.007561     0.005110      0.003044  \n",
       "2019-10-13 04:00:00                0.006019     0.005107      0.003822  \n",
       "...                                     ...          ...           ...  \n",
       "2025-11-26 06:00:00                0.006814     0.005511      0.003643  \n",
       "2025-11-26 07:00:00                0.006393     0.005483      0.003863  \n",
       "2025-11-26 08:00:00                0.007204     0.005481      0.003427  \n",
       "2025-11-26 09:00:00                0.005668     0.005495      0.004367  \n",
       "2025-11-26 10:00:00                0.008198     0.005503      0.003023  \n",
       "\n",
       "[53675 rows x 456 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean combined dataframe - only drop start and end NaNs, preserve middle for debugging\n",
    "# From analysis: 288 consecutive NaN rows at start, 0 at end\n",
    "\n",
    "rows_with_nans = combined_df.isna().any(axis=1)\n",
    "\n",
    "# Find first and last valid rows\n",
    "valid_rows = ~rows_with_nans\n",
    "valid_indices = combined_df[valid_rows].index\n",
    "\n",
    "if len(valid_indices) > 0:\n",
    "    first_valid = valid_indices[0]\n",
    "    last_valid = valid_indices[-1]\n",
    "    \n",
    "    # Count start and end NaNs\n",
    "    start_nans = rows_with_nans.loc[:first_valid].sum() - 1\n",
    "    end_nans = rows_with_nans.loc[last_valid:].sum() - 1\n",
    "    \n",
    "    print(f\"NaN Summary:\")\n",
    "    print(f\"  First valid row: {first_valid}\")\n",
    "    print(f\"  Last valid row: {last_valid}\")\n",
    "    print(f\"  Start NaNs to drop: {start_nans}\")\n",
    "    print(f\"  End NaNs to drop: {max(0, end_nans)}\")\n",
    "    \n",
    "    # Slice from first valid to last valid (inclusive)\n",
    "    combined_df_clean = combined_df.loc[first_valid:last_valid].copy()\n",
    "    \n",
    "    # Check for middle NaNs (these are preserved for inspection)\n",
    "    middle_nans = combined_df_clean.isna().any(axis=1).sum()\n",
    "    \n",
    "    print(f\"\\nAfter trimming start/end:\")\n",
    "    print(f\"  Rows: {len(combined_df_clean)} (from {combined_df_clean.index[0]} to {combined_df_clean.index[-1]})\")\n",
    "    print(f\"  Middle rows with NaNs: {middle_nans}\")\n",
    "    \n",
    "    if middle_nans > 0:\n",
    "        print(f\"  âš ï¸ WARNING: {middle_nans} rows with NaNs in middle - preserved for debugging\")\n",
    "else:\n",
    "    print(\"No valid rows found!\")\n",
    "    combined_df_clean = combined_df.iloc[0:0]  # Empty dataframe\n",
    "\n",
    "combined_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18260009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Analyzing Middle NaN Features\n",
      "======================================================================\n",
      "\n",
      "Features with middle NaNs: 4\n",
      "\n",
      "Top 20 features by NaN count:\n",
      "  regime_label                               96 NaNs ( 0.18%)\n",
      "  max_fwd_z_score                            96 NaNs ( 0.18%)\n",
      "  max_jump_z_score                           96 NaNs ( 0.18%)\n",
      "  vol_ratio_24h_144h                         23 NaNs ( 0.04%)\n",
      "\n",
      "Grouped by feature type:\n",
      "  max                     192 total NaNs\n",
      "  regime                   96 total NaNs\n",
      "  vol                      23 total NaNs\n",
      "\n",
      "Stochastic features with NaNs: 0\n",
      "  âœ“ No stochastic NaNs - fix is working!\n",
      "\n",
      "Date range of middle NaNs:\n",
      "  First: 2020-01-05 16:00:00\n",
      "  Last: 2020-01-09 16:00:00\n"
     ]
    }
   ],
   "source": [
    "# Analyze which features have the middle NaNs and verify stochastic fix\n",
    "if 'combined_df_clean' in globals() and len(combined_df_clean) > 0:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Analyzing Middle NaN Features\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get rows with NaNs\n",
    "    rows_with_middle_nans = combined_df_clean.isna().any(axis=1)\n",
    "    \n",
    "    if rows_with_middle_nans.sum() > 0:\n",
    "        # Count NaNs per feature\n",
    "        middle_nan_counts = combined_df_clean.isna().sum()\n",
    "        features_with_middle_nans = middle_nan_counts[middle_nan_counts > 0].sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\nFeatures with middle NaNs: {len(features_with_middle_nans)}\")\n",
    "        print(f\"\\nTop 20 features by NaN count:\")\n",
    "        for feat, count in features_with_middle_nans.head(20).items():\n",
    "            pct = (count / len(combined_df_clean)) * 100\n",
    "            print(f\"  {feat:40s} {count:4d} NaNs ({pct:5.2f}%)\")\n",
    "        \n",
    "        # Group by prefix\n",
    "        print(f\"\\nGrouped by feature type:\")\n",
    "        feature_groups = {}\n",
    "        for feat in features_with_middle_nans.index:\n",
    "            prefix = feat.split('_')[0] if '_' in feat else 'other'\n",
    "            if prefix not in feature_groups:\n",
    "                feature_groups[prefix] = 0\n",
    "            feature_groups[prefix] += features_with_middle_nans[feat]\n",
    "        \n",
    "        for prefix, total_nans in sorted(feature_groups.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {prefix:20s} {total_nans:6,} total NaNs\")\n",
    "        \n",
    "        # Check specifically for stochastic features\n",
    "        stoch_features_in_nans = [f for f in features_with_middle_nans.index if 'stoch' in f]\n",
    "        print(f\"\\nStochastic features with NaNs: {len(stoch_features_in_nans)}\")\n",
    "        if stoch_features_in_nans:\n",
    "            print(\"  âš ï¸ STOCHASTIC FIX NOT APPLIED! Should be 0.\")\n",
    "            for feat in stoch_features_in_nans:\n",
    "                print(f\"    {feat}: {features_with_middle_nans[feat]} NaNs\")\n",
    "        else:\n",
    "            print(\"  âœ“ No stochastic NaNs - fix is working!\")\n",
    "        \n",
    "        # Show date range of NaN occurrences\n",
    "        nan_dates = combined_df_clean[rows_with_middle_nans].index\n",
    "        print(f\"\\nDate range of middle NaNs:\")\n",
    "        print(f\"  First: {nan_dates[0]}\")\n",
    "        print(f\"  Last: {nan_dates[-1]}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nâœ“ No middle NaNs found!\")\n",
    "else:\n",
    "    print(\"No data to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate why regime_label has NaNs in Jan 2020\n",
    "print(\"=\" * 70)\n",
    "print(\"Investigating Regime Label NaNs\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the rows with regime NaNs\n",
    "regime_nans = combined_df_clean['regime_label'].isna()\n",
    "nan_rows = combined_df_clean[regime_nans]\n",
    "\n",
    "print(f\"\\nTotal rows with regime_label NaN: {regime_nans.sum()}\")\n",
    "print(f\"Date range: {nan_rows.index[0]} to {nan_rows.index[-1]}\")\n",
    "\n",
    "# Check if this is a continuous block\n",
    "print(f\"\\nFirst 10 NaN timestamps:\")\n",
    "for ts in nan_rows.index[:10]:\n",
    "    print(f\"  {ts}\")\n",
    "\n",
    "# Check the raw data around this period\n",
    "if 'raw_history' in globals():\n",
    "    print(f\"\\nChecking raw data around NaN period:\")\n",
    "    check_start = nan_rows.index[0] - pd.Timedelta(hours=24)\n",
    "    check_end = nan_rows.index[-1] + pd.Timedelta(hours=24)\n",
    "    \n",
    "    raw_slice = raw_history.loc[check_start:check_end]\n",
    "    print(f\"  Raw data rows in this period: {len(raw_slice)}\")\n",
    "    print(f\"  Expected rows (hourly): {int((check_end - check_start).total_seconds() / 3600)}\")\n",
    "    \n",
    "    # Check for gaps\n",
    "    if len(raw_slice) > 0:\n",
    "        time_diffs = raw_slice.index.to_series().diff()\n",
    "        gaps = time_diffs[time_diffs > pd.Timedelta(hours=1)]\n",
    "        if len(gaps) > 0:\n",
    "            print(f\"\\n  âš ï¸ Found {len(gaps)} time gaps:\")\n",
    "            for gap_time, gap_size in gaps.items():\n",
    "                print(f\"    {gap_time}: {gap_size}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ No time gaps found\")\n",
    "\n",
    "# Check what features look like during this period\n",
    "print(f\"\\nFeature values during NaN period (first NaN row):\")\n",
    "first_nan_row = combined_df_clean.loc[nan_rows.index[0]]\n",
    "print(f\"  vol_rs_24h: {first_nan_row.get('vol_rs_24h', 'N/A')}\")\n",
    "print(f\"  vol_rs_72h: {first_nan_row.get('vol_rs_72h', 'N/A')}\")\n",
    "print(f\"  trend_strength_24h: {first_nan_row.get('trend_strength_24h', 'N/A')}\")\n",
    "print(f\"  logret_24h: {first_nan_row.get('logret_24h', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8948a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes:\n",
      "  Train: 42,940 rows (80.0%)\n",
      "  Val:   5,367 rows (10.0%)\n",
      "  Test:  5,368 rows (10.0%)\n",
      "\n",
      "X shapes -> train (42940, 450), val (5367, 450), test (5368, 450)\n",
      "y shapes -> train (42940, 6), val (5367, 6), test (5368, 6)\n",
      "\n",
      "âš  NaNs found:\n",
      "  Train: 23 NaNs\n"
     ]
    }
   ],
   "source": [
    "# Split into train/val/test (80/10/10)\n",
    "n_samples = len(combined_df_clean)\n",
    "train_end = int(n_samples * 0.8)\n",
    "val_end = train_end + int(n_samples * 0.1)\n",
    "\n",
    "# Get feature and target columns\n",
    "feature_cols = features.columns.intersection(combined_df_clean.columns)\n",
    "target_cols = targets.columns.intersection(combined_df_clean.columns)\n",
    "\n",
    "X_train = combined_df_clean[feature_cols].iloc[:train_end]\n",
    "X_val = combined_df_clean[feature_cols].iloc[train_end:val_end]\n",
    "X_test = combined_df_clean[feature_cols].iloc[val_end:]\n",
    "\n",
    "y_train = combined_df_clean[target_cols].iloc[:train_end]\n",
    "y_val = combined_df_clean[target_cols].iloc[train_end:val_end]\n",
    "y_test = combined_df_clean[target_cols].iloc[val_end:]\n",
    "\n",
    "print(f\"Split sizes:\")\n",
    "print(f\"  Train: {len(X_train):,} rows ({len(X_train)/n_samples*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(X_val):,} rows ({len(X_val)/n_samples*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(X_test):,} rows ({len(X_test)/n_samples*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nX shapes -> train {X_train.shape}, val {X_val.shape}, test {X_test.shape}\")\n",
    "print(f\"y shapes -> train {y_train.shape}, val {y_val.shape}, test {y_test.shape}\")\n",
    "\n",
    "# Final NaN check on all splits\n",
    "train_nans = X_train.isna().sum().sum()\n",
    "val_nans = X_val.isna().sum().sum()\n",
    "test_nans = X_test.isna().sum().sum()\n",
    "\n",
    "if train_nans + val_nans + test_nans == 0:\n",
    "    print(\"\\nâœ“ No NaNs in any split - ready for training!\")\n",
    "else:\n",
    "    print(f\"\\nâš  NaNs found:\")\n",
    "    if train_nans > 0:\n",
    "        print(f\"  Train: {train_nans} NaNs\")\n",
    "    if val_nans > 0:\n",
    "        print(f\"  Val: {val_nans} NaNs\")\n",
    "    if test_nans > 0:\n",
    "        print(f\"  Test: {test_nans} NaNs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
